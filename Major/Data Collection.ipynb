{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import chromedriver_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "chromedriver=\"C:\\Python36\\Scripts\\chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.transtats.bts.gov/ONTIME/Departures.aspx'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function automates the process of downloading csvs from 'https://www.transtats.bts.gov/ONTIME/Departures.aspx'\n",
    "# by changing airport/airline fields as needed.\n",
    "\n",
    "def get_stats(driver, airport_name, airline_name, month_number):\n",
    "    \n",
    "    driver.get(url)\n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.HOME) \n",
    "    time.sleep(5)\n",
    "    #soup = BeautifulSoup(driver.page_source, 'html.parser') \n",
    "    send_button = driver.find_element_by_xpath('//*[@id=\"chkAllStatistics\"]') \n",
    "    send_button.click() \n",
    "    driver.execute_script(\"window.scrollTo(0, 150)\")\n",
    "    \n",
    "    #time.sleep(15)\n",
    "    airport = driver.find_element_by_xpath('//*[@id=\"cboAirport\"]')\n",
    "    airport.click() \n",
    "    airport.send_keys(airport_name) \n",
    "    \n",
    "    #time.sleep(15)\n",
    "    airline = driver.find_element_by_xpath('//*[@id=\"cboAirline\"]') \n",
    "    airline.click() \n",
    "    airline.send_keys(airline_name) \n",
    "    \n",
    "   # time.sleep(15)\n",
    "    m_pat = '//*[@id=\"chkMonths_' + str(month_number) + '\"]'\n",
    "    month = driver.find_element_by_xpath(m_pat) \n",
    "    month.click() \n",
    "    \n",
    "   # time.sleep(15)\n",
    "    days = driver.find_element_by_xpath('//*[@id=\"chkAllDays\"]')\n",
    "    days.click() \n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(150, 500)\")\n",
    "   # time.sleep(15)\n",
    "    years = driver.find_element_by_xpath('//*[@id=\"chkYears_31\"]')\n",
    "    years.click() \n",
    "\n",
    "    submit = driver.find_element_by_xpath('//*[@id=\"btnSubmit\"]')\n",
    "    submit.click() \n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    download = driver.find_element_by_xpath('//*[@id=\"DL_CSV\"]') \n",
    "    download.click() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'San Francisco'\n",
    "\n",
    "#air_name = 'United'\n",
    "\n",
    "plane_lines = ['Southwest', 'Delta', 'United', 'American']\n",
    "#plane_lines1 = ['Delta', 'United', 'American']\n",
    "#plane_lines2 = ['Southwest', 'Delta', 'American']\n",
    "\n",
    "month_nums = [0,3,5,9]\n",
    "\n",
    "\n",
    "for num in month_nums:\n",
    "    for p_name in plane_lines:\n",
    "        get_stats(driver, city, p_name, num) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,144): \n",
    "    \n",
    "    tag = 'EMPTY'\n",
    "    \n",
    "    if i <= 15:\n",
    "        tag = 'SFO'\n",
    "    elif i > 15 and i <= 31:\n",
    "        tag = 'SEA'\n",
    "    elif i > 31 and i <= 47:\n",
    "        tag = 'PHX'\n",
    "    elif i > 47 and i <= 55:\n",
    "        tag = 'JFK'\n",
    "    elif i > 55 and i <= 63:\n",
    "        tag = 'LGA'\n",
    "    elif i > 63 and i<= 75:\n",
    "        tag = 'IAH'\n",
    "    elif i > 75 and i <= 87:\n",
    "        tag = 'HNL'\n",
    "    elif i > 87 and i <= 103:\n",
    "        tag = 'BNA'\n",
    "    elif i > 103 and i <= 115:\n",
    "        tag = 'STL'\n",
    "    elif i > 115 and i <= 127:\n",
    "        tag = 'CMH'\n",
    "    elif i > 127 and i <= 143:\n",
    "        tag = 'CLE'\n",
    "        \n",
    "    url = 'Detailed_Statistics_Departures (' + str(i) + ')' + '.csv'\n",
    "    print(url)  \n",
    "    new_df = pd.read_csv(url, skiprows=6)\n",
    "    new_df['Origin'] = tag\n",
    "    df = df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Carrier Code'] != ' SOURCE: Bureau of Transportation Statistics'] \n",
    "#df.to_pickle(\"flight_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.wunderground.com/history/monthly/us/ca/san-francisco/KSFO/date/2018-1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_scrape(driver, my_cols, month_dict, my_url, tag):\n",
    "    #my_url = all_urls[0][1]\n",
    "    #current_tag = all_urls[0][0]\n",
    "    driver.get(my_url)\n",
    "    time.sleep(10)\n",
    "    tables = pd.read_html(driver.page_source)\n",
    "    \n",
    "    first_df = pd.concat([tables[3], tables[4], tables[5], tables[6], tables[7], tables[8]], axis=1)\n",
    "    first_df = first_df.iloc[1:]\n",
    "    first_df.columns = my_cols\n",
    "    first_df.reset_index(inplace=True, drop=True)\n",
    "    month = tables[2][0][0]\n",
    "    prefix = month_dict[month]\n",
    "    \n",
    "    date_list = []\n",
    "\n",
    "    to_iter = {'Jan' : 32, 'Apr' : 31, 'Jun' : 31, 'Oct' : 32}\n",
    "    \n",
    "    for i in range (1,to_iter[month]):\n",
    "        date = prefix + '/' + str(i) + '/' + '2018'\n",
    "        date_list.append(date)\n",
    "\n",
    "    first_df['Date'] = date_list\n",
    "    first_df['Origin'] = tag\n",
    "    \n",
    "    return first_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'Jan' : '01', 'Apr' : '04', 'Jun' : '06', 'Oct' : '10' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_urls = ['https://www.wunderground.com/history/monthly/us/ca/san-francisco/KSFO/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/wa/seattle/KSEA/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/az/phoenix/KPHX/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/ny/new-york-city/KJFK/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/tx/houston/KIAH/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/hi/honolulu/PHNL/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/tn/nashville/KBNA/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/mo/st.-louis/KSTL/date/2018-',\n",
    "                'https://www.wunderground.com/history/monthly/us/oh/columbus/KCMH/date/2018-',              \n",
    "               ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.read_pickle('flight_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_names = main['Origin'].unique() .tolist()\n",
    "port_names = port_names[:-1]\n",
    "port_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = ['1', '4', '6', '10']\n",
    "all_urls = []  \n",
    "index = -1\n",
    "for port in airport_urls:\n",
    "    index += 1\n",
    "    for s in suffix:\n",
    "        final_url = port + s\n",
    "        all_urls.append((port_names[index], final_url))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in all_urls:\n",
    "    curr_df = easy_scrape(driver, my_cols, month_dict, link[1], link[0] )\n",
    "    weather_df = weather_df.append(curr_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_df.to_pickle('with_rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_pickle('with_rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['Origin', 'Date', 'Min_Temperature', 'Avg_Temperature', 'Max_Temperature', 'Min_DewPoint',\n",
    "       'Avg_DewPoint', 'Max_DewPoint', 'Min_Humidity', 'Avg_Humidity',\n",
    "       'Max_Humidity', 'Min_Wind', 'Avg_Wind', 'Max_Wind', 'Min_Pressure',\n",
    "       'Avg_Pressure', 'Max_Pressure', 'Precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df[new_cols]\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date(date):\n",
    "    if len(date) == 9:\n",
    "        date = date[:2] + '/0' + date[3:]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = weather_df.copy()\n",
    "cp.reset_index(inplace=True,drop=True)\n",
    "cp['Date'] = cp['Date'].apply(change_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp.to_pickle('with_rain_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = pd.read_pickle('flight_stats')\n",
    "weather_df = pd.read_pickle('with_rain_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = flight_df.rename(columns={\"Date (MM/DD/YYYY)\" : \"Date\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['Origin',\n",
    "             'Date',\n",
    "             'Carrier Code',\n",
    "             'Flight Number',\n",
    "             'Tail Number',\n",
    "             'Destination Airport',\n",
    "             'Scheduled departure time',\n",
    "             'Actual departure time',\n",
    "             'Scheduled elapsed time (Minutes)',\n",
    "             'Actual elapsed time (Minutes)',\n",
    "             'Departure delay (Minutes)',\n",
    "             'Wheels-off time',\n",
    "             'Taxi-Out time (Minutes)',\n",
    "             'Delay Carrier (Minutes)',\n",
    "             'Delay Weather (Minutes)',\n",
    "             'Delay National Aviation System (Minutes)',\n",
    "             'Delay Security (Minutes)',\n",
    "             'Delay Late Aircraft Arrival (Minutes)',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = flight_df[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited = flight_df[flight_df['Origin'] != 'CLE']\n",
    "mer = edited.merge(weather_df, on=['Origin', 'Date']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer['Origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gates(place):\n",
    "    number_gates = {'SFO':115, 'SEA':80, 'PHX':116, 'JFK':128, 'LGA':72, 'IAH':130, 'HNL':47, 'BNA':42, 'STL':86, 'CMH':37}\n",
    "    return number_gates[place]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer['Num Gates'] = mer['Origin'].apply(get_gates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer.sample(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.Series(['Geeks', 'for', 'Geeks']) \n",
    "\n",
    "#unique_flights = pd.DataFrame(mer['Tail Number'].unique())\n",
    "\n",
    "#def get_age(tail_num):\n",
    "#    try:\n",
    "#        url = 'https://registry.faa.gov/aircraftinquiry/NNum_Results.aspx?NNumbertxt=' + str(tail_num)\n",
    "#        tables = pd.read_html(url, match = 'A/W Date')\n",
    "#        cert_date = tables[0][1][2]\n",
    "#        return cert_date\n",
    "#    except:\n",
    "#        return 'NaN'\n",
    "    \n",
    "#unique_flights['Cert_Date'] = unique_flights['Tail Number'].apply(get_age)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mer = mer[mer['Tail Number'] != 'N389AA'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_pickle('flight_ages')\n",
    "\n",
    "check = check[check['Cert_Date'] != 'NaN']\n",
    "\n",
    "final = mer.merge(check, on=['Tail Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = ['Scheduled elapsed time (Minutes)', 'Actual elapsed time (Minutes)', 'Flight Number']\n",
    "\n",
    "final = final.drop(columns=dropped_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = ['Origin', 'Date', 'Num Gates', 'Carrier Code', 'Tail Number', 'Cert_Date']\n",
    "cols = final.columns.tolist()\n",
    "\n",
    "new_cols = t_list + cols[4:-2]\n",
    "\n",
    "final = final[new_cols] \n",
    "\n",
    "final = final[final['Cert_Date'] != 'None']\n",
    "\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = final.copy()\n",
    "\n",
    "switch = switch.rename(columns={\"Min_Temperature\" : \"Max_Temp\", \"Max_Temperature\" : \"Min_Temp\"})\n",
    "switch = switch.rename(columns={\"Min_DewPoint\" : \"Max_Dew\", \"Max_DewPoint\" : \"Min_Dew\"})\n",
    "switch = switch.rename(columns={\"Min_Humidity\" : \"Max_Humid\", \"Max_Humidity\" : \"Min_Humid\"})\n",
    "switch = switch.rename(columns={\"Min_Wind\" : \"Max_Wind\", \"Max_Wind\" : \"Min_Wind\"})\n",
    "switch = switch.rename(columns={\"Min_Pressure\" : \"Max_Pressure\", \"Max_Pressure\" : \"Min_Pressure\"})\n",
    "\n",
    "switch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = switch.rename(columns={'Avg_Temperature' : 'Avg_Temp'})\n",
    "#switch.to_pickle('FINAL3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
